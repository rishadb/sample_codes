{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishadb/sample_codes/blob/main/3CNN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F00QH2B6CfkO",
        "outputId": "bb8e00cc-0ff1-445e-d416-4bcf3f5aec6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "total accuracy is 61.873999999999995%\n",
            "plane accuracy: 65.15544041450777%\n",
            "car accuracy: 80.9651474530831%\n",
            "bird accuracy: 49.32182490752158%\n",
            "cat accuracy: 47.20101781170484%\n",
            "deer accuracy: 47.58713136729222%\n",
            "dog accuracy: 59.00383141762452%\n",
            "frog accuracy: 66.19537275064268%\n",
            "horse accuracy: 64.07263294422827%\n",
            "ship accuracy: 72.10460772104608%\n",
            "truck accuracy: 65.29126213592234%\n",
            "total accuracy is 59.38%\n",
            "plane accuracy: 67.29559748427673%\n",
            "car accuracy: 82.43243243243244%\n",
            "bird accuracy: 49.67741935483871%\n",
            "cat accuracy: 48.38709677419355%\n",
            "deer accuracy: 36.96969696969697%\n",
            "dog accuracy: 55.4140127388535%\n",
            "frog accuracy: 61.78343949044586%\n",
            "horse accuracy: 55.70469798657718%\n",
            "ship accuracy: 72.8395061728395%\n",
            "truck accuracy: 61.963190184049076%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5938"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#CNN\n",
        "\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "#HP\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 2\n",
        "load_state = True\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((.5,.5,.5), (.5,.5,.5))])\n",
        "\n",
        "#load data\n",
        "train_dataset = torchvision.datasets.CIFAR10(download = True, root = \"//content/drive/MyDrive\", train = True, transform = transform )\n",
        "test_dataset = torchvision.datasets.CIFAR10(transform = transform, root = \"/content/drive/MyDrive\", train = False, download = True)\n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers= 2)\n",
        "test_loader = DataLoader(dataset = test_dataset, shuffle = True, batch_size = batch_size, num_workers = 2)\n",
        "train_dataset.classes #gives the classes in the dataset\n",
        "#custom Data  \n",
        "#data_dir = \"dataDirHere\"\n",
        "#img_datasets = {x: torchvision.dataset.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "#dataloaders = {x: DataLoader(dataset = img_datasets[x], shuffle = True, batch_size=batch_size) for x in ['train', 'val']}\n",
        "\n",
        "#defines:\n",
        "class NN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)# in_channels, out_channel, kernel size\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)#kerrnel size, stride\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)# n_out = ((n_in+ 2p - k)/s) + 1\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)#ouptput size of prev layer is 16-channel size,5-width,5-height as per the eqn\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.pool1(F.relu(self.conv1(x)))\n",
        "    x = self.pool1(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "#to save/ load checkpoint\n",
        "# def save_checkpoint(checkpoint, file = '/content/drive/MyDrive/Colab Notebooks/checkpoints/mycheckpoint.pth.tar'):\n",
        "#   print(\"=> saving checkpoint\")\n",
        "#   torch.save(checkpoint, file)\n",
        "\n",
        "# def load_checkpoint(location):\n",
        "#   print(\"=> loading checkpoint\")\n",
        "#   model.load_state_dict(checkpoint[\"model_dict\"])\n",
        "#   optimizer.load_state_dict(checkpoint[\"optim_dict\"])\n",
        "\n",
        "  # defenition:\n",
        "model = NN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "if load_state:\n",
        "  #loading saved params from file\n",
        "  loaded_states = torch.load(\"/content/drive/MyDrive/Colab Notebooks/checkpoints/mycheckpoint.pth.tar\")\n",
        "  model.load_state_dict(loaded_states[\"model_dict\"])\n",
        "  optimizer.load_state_dict(loaded_states[\"optim_dict\"])\n",
        "\n",
        "#train\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "#Saving the params to file\n",
        "  if epoch == num_epochs-1:\n",
        "    checkpoint = {'model_dict': model.state_dict(), 'optim_dict': optimizer.state_dict()}\n",
        "    torch.save(checkpoint, \"/content/drive/MyDrive/Colab Notebooks/checkpoints/mycheckpoint.pth.tar\") # predefined func to save checkpoint\n",
        "\n",
        "#save cpu, load cpu is the given case;\n",
        "#save gpu load cpu: torch.load(path, map_location = device_cpu) \n",
        "#both on gpu: model.to(device_cuda) after loading\n",
        "#save cpu load gpu: map_location = \"cuda:0\", model.to(device_cuda) after loading only\n",
        "\n",
        "  for data, targets in train_loader:\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device) \n",
        "    score = model(data)\n",
        "    loss = criterion(score, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "\n",
        "\n",
        "def acc(model, loader):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    classes = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "    n_samples = 0\n",
        "    n_correct = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "\n",
        "    for images, labels in loader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, predictions = outputs.max(1)\n",
        "      n_samples += labels.size(0)\n",
        "      n_correct += (predictions == labels).sum().item()\n",
        "      for i in range(10):\n",
        "        label = labels[i]\n",
        "        pred = predictions[i]\n",
        "        if label ==pred:\n",
        "          n_class_correct[label] +=1\n",
        "        n_class_samples[label] +=1\n",
        "\n",
        "  acc = n_correct/ n_samples\n",
        "  print(f\"total accuracy is {acc * 100}%\")\n",
        "  class_acc = [n_class_correct[i]/ n_class_samples[i] for i in range(10)]\n",
        "\n",
        "  for i in range(10):\n",
        "    print(f\"{classes[i]} accuracy: {class_acc[i] * 100}%\")\n",
        "\n",
        "  return acc\n",
        "\n",
        "\n",
        "acc(model, train_loader)\n",
        "acc(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPTFSaAPtDwg",
        "outputId": "76cea484-657c-42c3-861b-3d1b10c9ff4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Epoch 0/1\n",
            "----------\n",
            "train Loss: 1.1504 Acc: 0.6054\n",
            "val Loss: 1.0361 Acc: 0.6382\n",
            "\n",
            "Epoch 1/1\n",
            "----------\n",
            "train Loss: 0.9853 Acc: 0.6588\n",
            "val Loss: 1.0062 Acc: 0.6505\n",
            "\n",
            "Training complete in 0m 30s\n",
            "Best val Acc: 0.650500\n"
          ]
        }
      ],
      "source": [
        "#Transfer Learning\n",
        "  #import pretrained model\n",
        "#when making custom data, train, test folder, then folders with label name\n",
        "import torch, torchvision\n",
        "import time\n",
        "import copy\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "#HP\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 2\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((.5,.5,.5), (.5,.5,.5))])\n",
        "\n",
        "#load data\n",
        "train_dataset = torchvision.datasets.CIFAR10(download = True, root = \"//content/drive/MyDrive\", train = True, transform = transform )\n",
        "test_dataset = torchvision.datasets.CIFAR10(transform = transform, root = \"/content/drive/MyDrive\", train = False, download = True)\n",
        "image_datasets = {'train': train_dataset, 'val': test_dataset}\n",
        "#train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers= 2)\n",
        "dataloaders = {x: DataLoader(dataset = train_dataset if x=='train' else test_dataset, batch_size=batch_size, shuffle=True, num_workers= 2)\n",
        "               for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "print(class_names)\n",
        "\n",
        "\n",
        "class Identity(nn.Module): # takes in and returns same\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "#loading the model\n",
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False # freeze learning on pretrained params\n",
        "\n",
        "#print(model) #gives all layers in the model\n",
        "model.avgpool = Identity() #whole avgpool in the model replaced by identity\n",
        "model.classifier= nn.Linear(512, 10) #1st classifier layer turned to linear layer defined\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler = None, num_epochs=2):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train' and scheduler:\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "  \n",
        "model_t = train_model(model, criterion, optimizer)\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqpaH6uGDshR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "3CNN1.ipynb",
      "provenance": [],
      "mount_file_id": "1IrhdbzSeBVs7kl7VAshSB2p2R0h0Bi1h",
      "authorship_tag": "ABX9TyNMQh+X/iWC1Qwjh8hwPmYt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}